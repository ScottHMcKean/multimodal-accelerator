{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from maud.agent.config import parse_config\n",
    "import os\n",
    "\n",
    "root_dir = Path(os.getcwd()).parent\n",
    "config_path = root_dir / 'implementations' / 'agents' / 'openai' / 'config.yaml'\n",
    "agent_path = root_dir / 'implementations' / 'agents' / 'openai' / 'agent.py'\n",
    "\n",
    "mlflow_config = mlflow.models.ModelConfig(development_config=config_path)\n",
    "maud_config = parse_config(mlflow_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from databricks.sdk import WorkspaceClient\n",
    "w = WorkspaceClient()\n",
    "llm_client: OpenAI = w.serving_endpoints.get_open_ai_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from typing import List\n",
    "@mlflow.trace(span_type=\"RETRIEVER\", name=\"vector_search_retriever\")\n",
    "def retrieve_docs(query: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Performs vector search to retrieve relevant chunks.\n",
    "\n",
    "    Args:\n",
    "        query: Search query.\n",
    "        filters: Optional filters to apply to the search. Should follow the LLM-generated filter pattern of a list of field/filter pairs that will be converted to Databricks Vector Search filter format.\n",
    "\n",
    "    Returns:\n",
    "        List of retrieved Documents.\n",
    "    \"\"\"\n",
    "    traced_search = mlflow.trace(\n",
    "        w.vector_search_indexes.query_index,\n",
    "        name=\"_workspace_client.vector_search_indexes.query_index\",\n",
    "        span_type=\"FUNCTION\",\n",
    "    )\n",
    "\n",
    "    results = traced_search(\n",
    "        index_name=maud_config.retriever.index_name,\n",
    "        query_text=query,\n",
    "        columns=maud_config.retriever.mapping.all_columns,\n",
    "        **maud_config.retriever.parameters.model_dump(),\n",
    "    )\n",
    "    return results.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/10 12:53:00 WARNING mlflow.tracing.fluent: Failed to capture inputs for function query_index.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "VectorSearchIndexesAPI.query_index() got an unexpected keyword argument 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mretrieve_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is SQL?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:174\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WrappingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:162\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoro\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:145\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext._wrapping_logic\u001b[0;34m(fn, args, kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to capture inputs for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[1;32m    146\u001b[0m span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:175\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[0;32m--> 175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro\u001b[38;5;241m.\u001b[39msend(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36mretrieve_docs\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mPerforms vector search to retrieve relevant chunks.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    List of retrieved Documents.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m traced_search \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtrace(\n\u001b[1;32m     17\u001b[0m     w\u001b[38;5;241m.\u001b[39mvector_search_indexes\u001b[38;5;241m.\u001b[39mquery_index,\n\u001b[1;32m     18\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_workspace_client.vector_search_indexes.query_index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     span_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFUNCTION\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtraced_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaud_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaud_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmaud_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\u001b[38;5;241m.\u001b[39mas_dict()\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:174\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WrappingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrapping_coro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:162\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Since the function call occurs outside the coroutine,\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# if an exception occurs, we need to throw it back in, so that\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# we return control to the coro (in particular, so that the __exit__'s\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# of start_span and OTel's use_span can execute).\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoro\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:145\u001b[0m, in \u001b[0;36mtrace.<locals>._WrappingContext._wrapping_logic\u001b[0;34m(fn, args, kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to capture inputs for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m  \u001b[38;5;66;03m# sync/async function output to be sent here\u001b[39;00m\n\u001b[1;32m    146\u001b[0m span\u001b[38;5;241m.\u001b[39mset_outputs(result)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m result\n",
      "File \u001b[0;32m~/Repos/multimodal-accelerator/.venv/lib/python3.11/site-packages/mlflow/tracing/fluent.py:175\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WrappingContext(fn, args, kwargs) \u001b[38;5;28;01mas\u001b[39;00m wrapping_coro:\n\u001b[0;32m--> 175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m wrapping_coro\u001b[38;5;241m.\u001b[39msend(\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: VectorSearchIndexesAPI.query_index() got an unexpected keyword argument 'k'"
     ]
    }
   ],
   "source": [
    "retrieve_docs(query=\"What is SQL?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool_spec = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": maud_config.retriever.tool_name,\n",
    "            \"description\": maud_config.retriever.tool_description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"required\": [\"query\"],\n",
    "                \"additionalProperties\": False,\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"description\": \"query to look up in retriever\",\n",
    "                        \"type\": \"string\",\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "tool_functions = {maud_config.retriever.tool_name: self.retrieve_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True to VectorSearchClient().\n"
     ]
    }
   ],
   "source": [
    "from maud.agent.retrievers import get_vector_retriever\n",
    "retriever = get_vector_retriever(maud_config)\n",
    "\n",
    "from databricks_langchain import ChatDatabricks\n",
    "model = ChatDatabricks(endpoint=maud_config.model.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup some nodes to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from maud.agent.states import get_state\n",
    "from maud.agent.nodes import (\n",
    "    make_query_vector_database_node, \n",
    "    make_context_generation_node,\n",
    "    make_rephrase_generation_node,\n",
    "    make_simple_generation_node\n",
    ")\n",
    "\n",
    "state = get_state(maud_config)\n",
    "retriever_node = make_query_vector_database_node(retriever, maud_config)\n",
    "simple_generation_node = make_simple_generation_node(model, maud_config)\n",
    "context_generation_node = make_context_generation_node(model, maud_config)\n",
    "rephrase_generation_node = make_rephrase_generation_node(model, maud_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds a simple generation graph. It expects an input state with a dictionary of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.messages.input_examples import input_example\n",
    "input_state = {'messages':[{'type':'user', 'content':'What is SQL?'}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use langchain's convert_to_messages to convert the input state to a list of messages. This is convenient because OpenAI uses 'role' and LangChain uses 'type'. We centralize on LangChain's message type for now.\n",
    "\n",
    "This expects a list of dictionaries with 'type' and 'content' keys. Will fail is the entire {'messages':[{'type':'user', 'content':'What is SQL?'}]} is passed in.\n",
    "\n",
    "We can use the convert_to_openai_messages function to convert the list of LangChain messages back to a list of dictionaries with 'role' and 'content' keys.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages.utils import convert_to_messages\n",
    "lc_msgs = convert_to_messages(input_example['messages'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'So, yeah. Yes, it does support streaming, allowing you to watch your favorite shows and movies online.'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", simple_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check our rephrasing generation node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'user',\n",
       "   'content': 'What streaming capabilities does Apache Spark support for processing real-time data and incremental computation, as part of its unified analytics engine for large-scale data processing?'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", rephrase_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check context generation node with no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"I don't know. The provided context is empty, so I have no information to determine if something supports streaming.\"}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"generate\", context_generation_node)\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check retriever only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user', 'content': 'What is Apache Spark'},\n",
       "  {'role': 'assistant',\n",
       "   'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "  {'role': 'user', 'content': 'Does it support streaming?'}],\n",
       " 'context': 'Passage: Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =\\\\n Document URI: \\\\nPassage: 27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,\\\\n Document URI: \\\\nPassage: Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,\\\\n Document URI: \\\\n',\n",
       " 'documents': [Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 103079215112.0}, page_content='Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date ='),\n",
       "  Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 103079215116.0}, page_content='27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,'),\n",
       "  Document(metadata={'img_path': '', 'filename': 'FAA-2021-0268-0002.pdf', 'type': 'text', 'id': 111669149709.0}, page_content='Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"retrieve\", retriever_node)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds a rag graph without history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state)\n",
    "workflow.add_node(\"retrieve\", retriever_node)\n",
    "workflow.add_node(\"generate_w_context\", context_generation_node)\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate_w_context\")\n",
    "workflow.add_edge(\"generate_w_context\", END)\n",
    "app = workflow.compile()\n",
    "result = app.invoke(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'message': {'role': 'assistant',\n",
       "    'content': 'I do not know. The context appears to be a collection of unrelated data points with various codes, dates, and page numbers, but it does not provide any information about streaming capabilities.',\n",
       "    'refusal': None,\n",
       "    'name': None,\n",
       "    'tool_calls': None,\n",
       "    'tool_call_id': None},\n",
       "   'index': 0,\n",
       "   'finish_reason': 'stop',\n",
       "   'logprobs': None}],\n",
       " 'usage': None,\n",
       " 'id': None,\n",
       " 'model': None,\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1738970510,\n",
       " 'custom_outputs': {'message_history': [{'role': 'user',\n",
       "    'content': 'What is Apache Spark'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'Apache Spark is a unified analytics engine for large-scale data processing, providing high-level APIs in Java, Scala, Python, and R, and an optimized engine that supports general execution graphs. It has a rich set of higher-level tools, including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing. Apache Spark is capable of handling large-scale data processing, machine learning, and data analytics, making it a unified analytics engine.'},\n",
       "   {'role': 'user', 'content': 'Does it support streaming?'},\n",
       "   {'role': 'tool',\n",
       "    'content': 'Passage: Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =\\\\n Document URI: \\\\nPassage: 27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,\\\\n Document URI: \\\\nPassage: Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,\\\\n Document URI: \\\\n'},\n",
       "   {'role': 'tool',\n",
       "    'content': [{'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 103079215112.0},\n",
       "      'page_content': 'Ch-Se-Su = . , Effectivity = . , Page = 503. , Date = Jan 18/2005. , Effectivity = . , Page = 404. , Date = Sep 16/2009. , Ch-Se-Su = . , Effectivity = . , Page = 504. , Date = Jan 18/2005. , Effectivity = . , Page = 405. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 406. , Date = Feb 22/2021. , Ch-Se-Su = 27-41-09. , Effectivity = ALL. , Page = 401. , Date = May 21/2020. , Effectivity = . , Page = 407. , Date = Feb 16/2015. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Nov 04/2015. 27-33-05, Effectivity = ALL. 27-33-05, Page = . 27-33-05, Date = . 27-33-05, Ch-Se-Su = . 27-33-05, Effectivity = . 27-33-05, Page = . 27-33-05, Date = . , Effectivity = . , Page = 401. , Date = Feb 22/2021. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Jul 31/2018. , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Ch-Se-Su = . , Effectivity = . , Page = 405. , Date = Jul 31/2018. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 406. , Date = Jul 31/2018. , Effectivity = . , Page = 404. , Date = Nov 04/2015. , Ch-Se-Su = . , Effectivity = . , Page = 407. , Date = May 21/2020. , Effectivity = . , Page = 405. , Date = Aug 03/2010. , Ch-Se-Su = . , Effectivity = . , Page = 408. , Date = May 21/2020. , Effectivity = . , Page = 406. , Date =',\n",
       "      'type': 'Document'},\n",
       "     {'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 103079215116.0},\n",
       "      'page_content': '27-41-13, Date = Feb 06/2018. , Effectivity = . , Page = 402. , Date = Apr 26/2005. , Ch-Se-Su = . , Effectivity = . , Page = 514. , Date = Jun 03/2014. , Effectivity = . , Page = 403. , Date = Feb 09/2012. , Ch-Se-Su = 27-51-01. , Effectivity = ALL. , Page = 401. , Date = . , Effectivity = . , Page = . , Date = . , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Mar 04/2013. , Effectivity = . , Page = 404 405. , Date = Apr 26/2005 May 21/2020. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Mar 22/2004 Feb 16/2015. , Effectivity = . , Page = 406. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = 404. , Date = Nov 22/2012. , Effectivity = . , Page = 407. , Date = Jun 03/2014. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . 27-41-17, Effectivity = ALL. 27-41-17, Page = 401. 27-41-17, Date = Jul 31/2018. 27-41-17, Ch-Se-Su = . 27-41-17, Effectivity = . 27-41-17, Page = 202. 27-41-17, Date = Nov 04/2015. , Effectivity = . , Page = 402. , Date = Jul 31/2018. , Ch-Se-Su = 27-51-05. , Effectivity = ALL. , Page = 401. , Date = Feb 07/2019. , Effectivity = . , Page = 403. , Date = May 26/2010. , Ch-Se-Su = . , Effectivity = . , Page = 402. , Date = Jul 18/2006. , Effectivity = . , Page = 404. , Date = Nov 30/2011. , Ch-Se-Su = . , Effectivity = . , Page = 403. , Date = Jun 03/2014. , Effectivity = . , Page = 405. ,',\n",
       "      'type': 'Document'},\n",
       "     {'id': None,\n",
       "      'metadata': {'img_path': '',\n",
       "       'filename': 'FAA-2021-0268-0002.pdf',\n",
       "       'type': 'text',\n",
       "       'id': 111669149709.0},\n",
       "      'page_content': 'Date = Feb 06/2018 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 427. , Date = Nov 11/2020. , Effectivity = . , Page = 425. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 428. , Date = Nov 11/2020. , Effectivity = . , Page = 426. , Date = Nov 04/2015 20151104. , Ch-Se-Su = . , Effectivity = . , Page = 429. , Date = Nov 11/2020. , Effectivity = . , Page = . , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 427 428. , Date = . , Ch-Se-Su = . , Effectivity = ALL. , Page = 501. , Date = Nov 11/2020. , Effectivity = . , Page = 429. , Date = Feb 06/2018 20180206 Feb 27/2009 20090227. , Ch-Se-Su = 27-53-53. , Effectivity = . , Page = 502. , Date = Nov 11/2020. , Effectivity = . , Page = 430. , Date = Feb 27/2009 20090227. , Ch-Se-Su = . , Effectivity = . , Page = . , Date = . , Effectivity = . , Page = 431. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 503 504. , Date = Nov 04/2015 Nov 04/2015. , Effectivity = . , Page = 433. , Date = Feb 16/2015 20150216. , Ch-Se-Su = . , Effectivity = . , Page = 506. , Date = Sep 16/2009. , Effectivity = . , Page = . , Date = 20180206. , Ch-Se-Su = . , Effectivity = . , Page = 507. , Date = . , Effectivity = . , Page = 434. , Date = Feb 06/2018. , Ch-Se-Su = . , Effectivity = . ,',\n",
       "      'type': 'Document'}]}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from maud.agent.utils import graph_state_to_chat_type\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "chain = app | RunnableLambda(graph_state_to_chat_type)\n",
    "chain.invoke(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
